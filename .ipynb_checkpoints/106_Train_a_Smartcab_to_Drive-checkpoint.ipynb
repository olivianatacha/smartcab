{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Smartcab to drive - 106"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:rgb(50,150,50)\">Getting started</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">[OPTIONAL]Understand the world</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">Student provides a thorough discussion of the driving agent as it interacts with the environment.\n",
    "</span> \n",
    "\n",
    "##### <span style=\"color:rgb(183,28,28)\">Requires changes</span> \n",
    "\n",
    "<span style=\"color:rgb(200,150, 80)\">Feedback:</span>Great Observation and analysis of the simulation; the smartcab movement and the nature of rewards received by the driving agent.\n",
    "\n",
    "##### <span style=\"color:rgb(183,28,28)\">Amendment Required</span>\n",
    "**To meet specification**\n",
    "\n",
    "-Explain what happens **when** the red lights are turned on and the nature of the reward received by the driving agent.\n",
    "\n",
    "-Explain what happens **when** the green lights are turned on and the nature of the reward received by the driving agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">[OPTIONAL]\n",
    "Understand the Code</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">Student correctly addresses the questions posed about the Train a Smartcab to Drive code.\n",
    "\n",
    "</span> \n",
    "##### <span style=\"color:rgb(41,121,255)\">Meets Specification</span> \n",
    "<span style=\"color:rgb(200,150, 80)\">Feedback:</span>\n",
    "Excellent identification of the roles of agent.py, environment.py simulator.py and planner.py. The functions and variables implemented coorectly identified. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:rgb(50,150,50)\">Implement a basic Driving Agent</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">Basic Agent</span> \n",
    "##### <span style=\"color:rgb(50,50,50)\">Agent accepts input</span> \n",
    "##### <span style=\"color:rgb(50,50,50)\">Produces a valid output</span> \n",
    "##### <span style=\"color:rgb(50,50,50)\">Runs in a simulator</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">Driving agent produces a valid action when an action is required. Rewards and penalties are received in the simulation by the driving agent in accordance with the action taken.\n",
    "</span> \n",
    "##### <span style=\"color:rgb(41,121,255)\">Meets Specification</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">[OPTIONAL]\n",
    "Basic Agent Simulation Results</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">A visualization is included that correctly captures the results of the basic driving agent.\n",
    "\n",
    "</span> \n",
    "##### <span style=\"color:rgb(41,121,255)\">Meets Specification</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">Basic Agent Simulation Analysis</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">Student summarizes observations about the basic driving agent and its behavior. Optionally, if a visualization is included, analysis is conducted on the results provided.</span> \n",
    "\n",
    "##### <span style=\"color:rgb(41,121,255)\">Meets Specification</span> \n",
    "<span style=\"color:rgb(200,150, 80)\">Feedback:</span>\n",
    "Comprehensive examination of the agent simulation has been done and reported. Actions taken at given discrete inputs carefully noted and corresponding reactions by the smartcab described.\n",
    "The nature of decisions made and the effects of these decisions have been meticulously documented. The relaiabilityof the smartcab and the nature of rewards received have been detaily studied.\n",
    "\n",
    "\n",
    "Good job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:rgb(50,150,50)\">Inform the driving agent</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">Identify States</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">Student justifies a set of features that best model each state of the driving agent in the environment. Unnecessary features not included in the state (if applicable) are similarly justified.\n",
    "</span> \n",
    "\n",
    "##### <span style=\"color:rgb(183,28,28)\">Requires Change</span> \n",
    "\n",
    "<span style=\"color:rgb(200,150, 80)\">Feedback:</span>Beautiful Work! Careful choice and justification of relevant features for maintaining agent safety and efficiency. Clear basis for eliminating irrelevant features provided.\n",
    "\n",
    "##### <span style=\"color:rgb(183,28,28)\">Amend required</span> \n",
    "To meet specification, identify *the rest* of the relevant features.\n",
    "\n",
    "##### <span style=\"color:rgb(41,121,255)\">Tip</span> \n",
    "- Evaluate the contribution of the unstated features :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">Update Driving Agent State</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">The driving agent successfully updates its state based on the state definition and input provided.\n",
    "\n",
    "##### <span style=\"color:rgb(41,121,255)\">Meets Specification</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:rgb(50,150,50)\">Implement a Q-Learning Driving Agent</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">Q-Learning Agent</span> \n",
    "##### <span style=\"color:rgb(50,50,50)\">Agent updates Q-values</span> \n",
    "##### <span style=\"color:rgb(50,50,50)\">Picks the best action</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">The driving agent chooses the best available action from the set of Q-values for a given state. Additionally, the driving agent updates a mapping of Q-values for a given state correctly when considering the learning rate and the reward or penalty received.\n",
    "</span> \n",
    "\n",
    "\n",
    "##### <span style=\"color:rgb(41,121,255)\">Meets Specification</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">[OPTIONAL] Q-Learning Agent Simulation Results</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">A visualization is included that correctly captures the results of the initial/default Q-Learning driving agent.\n",
    "</span> \n",
    "##### <span style=\"color:rgb(41,121,255)\">Meets Specification</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">Q-Learning Agent Simulation Analysis</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">Student summarizes observations about the initial/default Q-Learning driving agent and its behavior, and compares them to the observations made about the basic agent. If a visualization is included, analysis is conducted on the results provided.\n",
    "</span> \n",
    "\n",
    "##### <span style=\"color:rgb(183,28,28)\">Requires Changes</span> \n",
    "\n",
    "<span style=\"color:rgb(200,150, 80)\">Feedback:</span>\n",
    "A comprehensive analysis of the agent simulation performed. A careful study of the trend of reliability, number of training trails and the number of safety and reliability rating are reported. Excellent work!\n",
    "\n",
    "##### <span style=\"color:rgb(183,28,28)\">Required Amends</span> \n",
    "To meet specification, ensure that the discussion answers the following questions;\n",
    "\n",
    "- Approximately how many training trials did the driving agent require before testing? Does that number make sense given the epsilon-tolerance?\n",
    "\n",
    "- Is the decaying function you implemented for Ïµ (the exploration factor) accurately represented in the parameters panel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:rgb(50,150,50)\">Improve the Q-Learning Driving Agent</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">Improved Q-Learning Agent</span> \n",
    "### <span style=\"color:rgb(50,50,50)\">Improvements Reported</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">The driving agent performs Q-Learning with alternative parameters or schemes beyond the initial/default implementation.\n",
    "</span> \n",
    "\n",
    "##### <span style=\"color:rgb(41,121,255)\">Meets Specification</span> \n",
    "\n",
    "<span style=\"color:rgb(200,150, 80)\">Feedback:</span>\n",
    "\n",
    "Neat reporting on improvements on the learning agent.\n",
    "\n",
    "\n",
    "| Attempt |  Epsilon - the exploration factor | Alpha | Tolerance | Safety | Reliability | n_test |\n",
    "| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| 1 | $$\\epsilon=\\frac{1}{t^2}$$ | 0.5 | 0.0001 | A+ | F | 10 |\n",
    "| 2 | $$\\epsilon=\\frac{1}{t^2 + at}$$ | 0.5 | 0.0001 | A+ | D | 10 |\n",
    "| 3 | $$\\epsilon=\\frac{1}{t^2 - at}$$ | 0.5 | 0.0001 | A+ | B | 10 |\n",
    "| 4 | $$\\epsilon=ABS(COS(at))$$ | 0.5 | 0.05 | F | C | 10 |\n",
    "| 5 | $$\\epsilon=ABS(COS(at))$$ | 0.1 | 0.05 | F | D | 10 |\n",
    "| 6 | $$\\epsilon=ABS(COS(at))$$ | 0.01 | 0.001 | A+ | A | 10 |\n",
    "| 7 | $$\\epsilon=\\frac{ASB(COS(at))}{t^2}$$ | 0.01 | 0.001 | F | F | 10 |\n",
    "| 8 | $$\\epsilon=\\frac{1}{t^2}$$ | 0.95 | 0.0005 | A+ | A | 10 |\n",
    "| 9 | $$\\epsilon=\\frac{1}{t^2}$$ | 0.95 | 0.00005 | C | A+ | 10 |\n",
    "| 10 | $$\\epsilon=\\frac{1}{t^2}$$ | 0.95 | 0.0001 | F | B | 10 |\n",
    "| 11 | $$\\epsilon=\\frac{1}{t^2}$$ | 0.7 | 0.0005 | F | A | 10 |\n",
    "| 12 | $$\\epsilon=\\frac{1}{t^2}$$ | 0.7 | 0.0001 | A | A | 10 |\n",
    "| 13 | $$\\epsilon=\\frac{1}{t^2}$$ | 0.97 | 0.0007 | A | B | 10 |\n",
    "| **14 Final** | **$$\\epsilon=ABS(COS(at))$$** | **0.01** | **0.001** | **A+** | **A** | **100** | \n",
    "\n",
    "Elaborate explanation of the trends and observations recorded in the improved implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">[OPTIONAL] Improved Q-Learning Agent Simulation Results </span> \n",
    "\n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">A visualization is included that correctly captures the results of the improved Q-Learning driving agent.\n",
    "</span> \n",
    "\n",
    "##### <span style=\"color:rgb(41,121,255)\">Meets Specification</span> \n",
    "<span style=\"color:rgb(200,150, 80)\">Feedback:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">Improved Q-Learning Agent Simulation Analysis</span> \n",
    "### <span style=\"color:rgb(50,50,50)\">Improvements reported</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">Student summarizes observations about the optimized Q-Learning driving agent and its behavior, and further compares them to the observations made about the initial/default Q-Learning driving agent. If a visualization is included, analysis is conducted on the results provided.</span>\n",
    "\n",
    "##### <span style=\"color:rgb(41,121,255)\">Meets Specification</span> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">Safety and Reliability</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">The driving agent is able to safely and reliably guide the Smartcab to the destination before the deadline. </span>\n",
    "\n",
    "##### <span style=\"color:rgb(41,121,255)\">Meets Specification</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">Define an Optimal Policy</span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">Student describes what an optimal policy for the driving agent would be for the given environment. The policy of the improved Q-Learning driving agent is compared to the stated optimal policy, and discussion is made as to whether the final driving agent commits to unusual or unexpected behavior based on the defined states. </span>\n",
    "\n",
    "##### <span style=\"color:rgb(183,28,28)\">Requires Changes</span> \n",
    "\n",
    "\n",
    "<span style=\"color:rgb(200,150, 80)\">Feedback:</span> Great efffort. The optimal policy elaborately presented.\n",
    "\n",
    "##### <span style=\"color:rgb(183,28,28)\">Amends Required</span> \n",
    "To meet specification, explain briefly for each state recorded from the simulation:\n",
    "- State  other examples (using the states you've defined) of what an optimal policy for this problem would look like\n",
    "- Is the policy (the action with the highest value) correct for the given state? \n",
    "- Are there any states where the policy is different than what would be expected from an optimal policy?\n",
    "-  Provide an example of a state and all state-action rewards recorded, and explain why it is the correct policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:rgb(50,50,50)\">[OPTIONAL] Future Rewards </span> \n",
    "\n",
    "- #### <span style=\"color:rgb(183,28,28)\">Student correctly identifies the two characteristics about the project that invalidate the use of future rewards in the Q-Learning implementation. </span>\n",
    "\n",
    "##### <span style=\"color:rgb(183,28,28)\">Requires changes</span> \n",
    "\n",
    "<span style=\"color:rgb(200,150, 80)\">Feedback:</span> The characteristics required have not been provided.\n",
    "\n",
    "##### <span style=\"color:rgb(183,28,28)\">Amendment required</span>\n",
    "To meet specification,state two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:rgb(41,121,255)\">Remark</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback: Great work! Excellent implementation of this project with clear and concise documentation of required reports. Reviewing this work has been a great pleasure.\n",
    "\n",
    "- Do well to submit the html report of the work for the final submisssion. \n",
    "- Correct use of grammar will also enhance the quality of the work, it is highly encouraged. This [resource](https://www.grammarly.com/) should be helpful in this area.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
